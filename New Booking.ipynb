{"cells":[{"cell_type":"markdown","source":["# Introduction\n\nThe aim is to predict which country a new user's first booking destination will be. In the data available, we are given a list of users along with their demographics, web session records, and some summary statistics. All the users in this dataset are from the USA.\n\nThere are 12 possible outcomes of the destination country: 'US', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU', 'NDF' (no destination found), and 'other'. Note that 'NDF' is different from 'other' because 'other' means there was a booking, but is to a country not included in the list, while 'NDF' means there wasn't a booking.\n\nThe training and test sets we got from Kaggle are splitted by date. In the test set, we will predict all the new users with first activities after 7/1/2014. \n\nThe datasets are:\n\n1- train_users.csv - the training set of users <br>\n2- test_users.csv - the test set of users\n\n* id: user id\n* date_account_created: the date of account creation\n* timestamp_first_active: timestamp of the first activity, note that it can be earlier than date_account_created or date_first_booking because a user can search before signing up\n* date_first_booking: date of first booking\n* gender\n* age\n* signup_method\n* signup_flow: the page a user came to signup up from\n* language: international language preference\n* affiliate_channel: what kind of paid marketing\n* affiliate_provider: where the marketing is e.g. google, craigslist, other\n* first_affiliate_tracked: whats the first marketing the user interacted with before the signing up\n* signup_app\n* first_device_type\n* first_browser\n* country_destination: this is the target variable you are to predict\n\nWe will go through the following steps:\n* Fetch Airbnb data\n* Merge the test_users.csv and train_users.csv\n* Clean the data\n* Display the data\n* Explore the new Dataframe\n* Explore other data sets\n* Create Assumptions, develop hypothesis, and create relationship\n* Build Predictive Model\n* Evaluate Model and calculated deviation of the predicted output\n\nWe will also show the different sub-steps that can be taken to reach the presented solution.\n\nAs we begin the study, we first need to ensure that the datasets are clean and that all irrelevant parts are removed or filled correctly."],"metadata":{}},{"cell_type":"code","source":["%matplotlib inline\nimport numpy as np # library for working with Arrays\nimport pandas as pd # makes working with data tables easier\nimport matplotlib.pyplot as plt # module for plotting\nimport seaborn as sns #\nfrom pyspark.sql.functions import * \n\n\nfrom sklearn import ensemble\nfrom sklearn import linear_model\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.cross_validation import train_test_split\nimport sklearn.metrics as metrics\nfrom collections import Counter\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df_train_users = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option('inferSchema', 'true')\\\n  .load(\"/FileStore/tables/train_users_ru.csv\")\n  \ndisplay(df_train_users)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df_test_users = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option('inferSchema', 'true')\\\n  .load(\"/FileStore/tables/test_users_ru.csv\")\n  \ndisplay(df_test_users)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["We checked both train_users and test_users to understand the content of the data.\nThe results of the analysis are as followed:\n1. The attributes of both data sets are similar\n2. There is 1 additional column that is different in the train_users.csv data set titled country_destination and add new column to test dataframe\n3. There are many irrelevant parts that needs to be resolved in the data sets"],"metadata":{}},{"cell_type":"code","source":["new_test = df_test_users.withColumn(\"country_destination\",  lit(None))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["# Merging\nFrom the analysis we can deduce that the test_users is an extension from the train_users dataset. Therefore we can merge the datasets to streamline the data cleaning phase."],"metadata":{}},{"cell_type":"code","source":["users = df_train_users.union(new_test)\ndisplay(users)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["users.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Cleaning Data\n\nThere are many null values for some columns. Now, we have applied values to represent to represent them. This action was completed so that we may be able to develop models on the complete set of users to easily identify patterns as we proceed with the analysis.\n\nThe values added to the Null values are as followed:\n* Age >> 0\n* dountry_destination >> NDF\n* date_first_booking >> -unknown-\n* first_affiliate_tracked >> untracked"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":[" cleanedTrainingData = users.na.fill({'age': 0, 'date_first_booking': '-unknown-', 'country_destination' :'NDF', 'first_affiliate_tracked' : 'untracked'})\n display(cleanedTrainingData)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["# Hypothesis\n\nWe believe that these unseen characteristics(age, gender, timestamp first active, signup flow, affiliate provider, date account create and date of first booking) have a direct influence on the country of travel. We will illustrate these characteristics in various diagrams and then we will perform a cross analysis to explore the possible combination of influences to see if the results effect the decision of country of travel."],"metadata":{}},{"cell_type":"code","source":["sqlContext.registerDataFrameAsTable(cleanedTrainingData,\"users_table\")\nnewVal = sqlContext.sql(\"select age from users_table\").collect()\nfig = sns.distplot(newVal)\nplt.xlabel('Age')\nplt.ylabel('Distribution Percentage')\n\ndisplay()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["This distribution plot illustrates the percetange of the total population of users.\n<br>\n<br>\nNote: It can be observed that there is still inconsistencies with our data due to the age range extending to 1000+. So we will assume that life expectancy ends at the age of 90 and any values above 90 will be converted to 0."],"metadata":{}},{"cell_type":"code","source":["new_cleaned = cleanedTrainingData.withColumn(\"age\", when(col(\"age\")>90, 0).otherwise(col(\"age\")) )\n\ndisplay(new_cleaned)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["Remember that 0 indicates all NULL entries and entries that exceed the age of 90. However, because of total count of the zeros and the frequency at which users input their age for their first booking we gain further understanding that age does not influence the decision to choose a specific destination."],"metadata":{}},{"cell_type":"code","source":["sqlContext.registerDataFrameAsTable(new_cleaned,\"users_table\")\nnewVal = sqlContext.sql(\"select age from users_table\").collect()\nsns.distplot(newVal, kde = False)\nplt.xlabel('Age')\nplt.ylabel('Population Size')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["gender_df = new_cleaned.groupby(\"gender\").count()\ndisplay(gender_df)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["This pie chart illustrates the distribution of users between female, male, other, and unknown. \"Other\" indicates users that do not want to identify themselves as male or female and Unknown indicates users that have not enter any value for the gender category."],"metadata":{}},{"cell_type":"code","source":["# Updating the users dataframe column that contains gender with values.\n# Unknown: 0\n# Male: 1\n# Female: 2\ndef gender_id(gender):\n    if gender == \"MALE\":\n        return 1\n    if gender == \"FEMALE\":\n        return 2\n    return 0\n\nfunc_udf = udf(gender_id)\nnext_clean = new_cleaned.withColumn('gender',func_udf(new_cleaned['gender']))\ndisplay(next_clean)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Note: From a quick observation we can see that gender in another characteristic that does not influence on choice of destination. But because unknown values encompasses 47% of the data results, we must all see if the unknown category changes the decision result."],"metadata":{}},{"cell_type":"markdown","source":["# Creation of Decision Tree\n\nIn this section of code, we will begin to analyze the details contained with the .csv file and formulate a determination about the countries that a user will likely travel to next. It is evidenced through the above figure that users are primarily booking reservations in the US or not booking a reservation at all.\n\nOf the possible destination countries of travel ('US', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU', 'NDF','other'), we can derive from the figure above that the difference between male and female travel destinations are almost evenly distributed.\nSince there isn't much variance, we will add elements of age to determine if it has any significance on the output of the data"],"metadata":{}},{"cell_type":"code","source":["# Import 'tree' from scikit-learn library\nfrom sklearn import tree"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Updating the users dataframe column that contains gender with values.\n# NDF=0 US=1 FR=2 CA=3 GB=4 ES=5 \n# IT=6 PT=7 NL=8 DE=9 AU=10 other=11\n\ndef get_country_id(country):\n    if country == \"NDF\":\n        return 0\n    if country == \"US\":\n        return 1\n    if country == \"FR\":\n        return 2\n    if country == \"CA\":\n        return 3\n    if country == \"GB\":\n        return 4\n    if country == \"ES\":\n        return 5\n    if country == \"IT\":\n        return 6\n    if country == \"PT\":\n        return 7\n    if country == \"NL\":\n        return 8\n    if country == \"DE\":\n        return 9\n    if country == \"AU\":\n        return 10\n    if country == \"other\":\n        return 11\n      \n\nfunc_udf = udf(get_country_id)\ncountry_vals = new_cleaned.withColumn('country_destination',func_udf(new_cleaned['country_destination']))\ndisplay(country_vals)\n\n#country_vals.printSchema()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["sqlContext.registerDataFrameAsTable(country_vals,\"users_table\")\ntarget = sqlContext.sql(\"select country_destination from users_table\").collect()\nfeatures_one = sqlContext.sql(\"select timestamp_first_active,signup_flow,age from users_table\").collect()\n\n# Fit your first decision tree: my_tree_one\nmy_tree_one = tree.DecisionTreeClassifier()\nmy_tree_one = my_tree_one.fit(features_one, target)\n\nprint(my_tree_one.feature_importances_)\nprint(my_tree_one.score(features_one, target))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["# Quick Note\n\nOne way to quickly see the result of your decision tree is to see the importance of the features that are included. This is done by requesting the .feature_importances_attribute of your tree object. Another quick metric is the mean accuracy that you can compute using the .score() function with features_one and target as arguments.\n\nLook at the importance and score of the included features. The features are printed in the order that they are created and called."],"metadata":{}},{"cell_type":"markdown","source":["# First Prediction"],"metadata":{}},{"cell_type":"code","source":["my_prediction = my_tree_one.predict(features_one)\ndf =  pd.DataFrame(my_prediction,columns = [\"country_destination\"])\n\nA=sqlContext.sql(\"select id from users_table\").collect()\nsample = pd.DataFrame(A, columns=[\"id\"]) \n\nframes = [sample,df]\nresult = pd.concat(frames,axis=1)\n\nprint result"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["spark_df = sqlContext.createDataFrame(result)\ndisplay(spark_df)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["# Second Prediction"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n\n# Train data is the dataframe that is continously modified while train dataframe is static\ntrain, test = country_vals.randomSplit([0.8, 0.2], seed=12345)\n\n# Create the target and features: target, features_one\nsqlContext.registerDataFrameAsTable(test,\"test_table\")\nsqlContext.registerDataFrameAsTable(train,\"train_table\")\ntarget = sqlContext.sql(\"select country_destination from test_table\").collect()\nfeatures_one = sqlContext.sql(\"select timestamp_first_active,signup_flow,age  from test_table\").collect()\n\n# Fit your first decision tree: my_tree_one\nmy_tree_one = tree.DecisionTreeClassifier()\nmy_tree_one = my_tree_one.fit(features_one, target)\n\n#One way to quickly see the result of your decision tree is to see the importance of the features that are included. \n#This is done by requesting the .feature_importances_ attribute of your tree #object. Another quick metric is the mean \n#accuracy that you can compute using the .score() #function with features_one and target as arguments.\n\n#Look at the importance and score of the included features...\n\n#NOTE: The features are printed in the order that they are created and called\n\nprint(my_tree_one.feature_importances_)\nprint(my_tree_one.score(features_one, target))\n\n# Extract the features from the test set: \"timestamp_first_active\", \"signup_flow\", \"age\".\ntrain_features = sqlContext.sql(\"select timestamp_first_active,signup_flow,age  from train_table\").collect()\n\n# Make your prediction using the test set\nmy_prediction = my_tree_one.predict(train_features)\n\n# Create a data frame with two columns: userid & country_destination. country_destination contains the predictions\ndf =  pd.DataFrame(my_prediction,columns = [\"country_destination\"])\n\nA=sqlContext.sql(\"select id from test_table\").collect()\nsample = pd.DataFrame(A, columns=[\"id\"]) \n\nframes = [sample,df]\nresult = pd.concat(frames,axis=1)\nprint result\n"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["#display(features_one)\nsqlContext.registerDataFrameAsTable(country_vals,\"users_table\")\nsample = sqlContext.sql(\"select country_destination,timestamp_first_active,signup_flow,age  from users_table\")\nsample2 = sqlContext.sql(\"select timestamp_first_active,signup_flow,age  from users_table\")\n\n#sample.printSchema()\nsample = sample.select(col('timestamp_first_active'),col('signup_flow'),col('age'),col('country_destination'), sample.country_destination.cast('integer').alias(\"new_country\"))\n\ndisplay(sample2)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["display(country_vals)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["\nfrom pyspark.ml.feature import VectorAssembler, VectorIndexer\nfeaturesCols = sample.columns\nfeaturesCols.remove('country_destination')\nfeaturesCols.remove('new_country')\n\ntrain, test = sample.randomSplit([0.7, 0.3])\n\n# This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\nvectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n# This identifies categorical features and indexes them.\nvectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=4)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\n# Takes the \"features\" column and learns to predict \"cnt\"\ngbt = GBTRegressor(labelCol=\"new_country\")"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n# Define a grid of hyperparameters to test:\n#  - maxDepth: max depth of each decision tree in the GBT ensemble\n#  - maxIter: iterations, i.e., number of trees in each GBT ensemble\n# In this example notebook, we keep these values small.  In practice, to get the highest accuracy, you would likely want to try deeper trees (10 or higher) and more trees in the ensemble (>100).\nparamGrid = ParamGridBuilder()\\\n  .addGrid(gbt.maxDepth, [2, 5])\\\n  .addGrid(gbt.maxIter, [10, 100])\\\n  .build()\n# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n# Declare the CrossValidator, which runs model tuning for us.\ncv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, cv])"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["pipelineModel = pipeline.fit(train)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["predictions = pipelineModel.transform(test)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["display(predictions.select(\"new_country\", \"prediction\", *featuresCols))"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["rmse = evaluator.evaluate(predictions) \nprint \"Deviation of our test set: %g\" % rmse"],"metadata":{},"outputs":[],"execution_count":41}],"metadata":{"name":"Sample2","notebookId":3893077915670758},"nbformat":4,"nbformat_minor":0}
